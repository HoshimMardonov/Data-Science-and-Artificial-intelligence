{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JfHmrNmmPo3NFrVJaAgjLKfcCWFYia-h",
      "authorship_tag": "ABX9TyMryGZsO74n7rvL/N0WPblW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoshimMardonov/Datasets/blob/main/graduate_admissions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "Vi93WjNaDKuk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load dataFrame using the pandas library\n"
      ],
      "metadata": {
        "id": "T0amMTlTEgDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Rhtyme/ml_uz_book/main/practice_session/Multivariate_linear_regression_4_6/Admission_Predict.csv\")"
      ],
      "metadata": {
        "id": "qgYH0cjuDvIV"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Let's get acquainted with the database, that is, what columns there are, and what the data in them looks like, etc.***"
      ],
      "metadata": {
        "id": "oC5QOITaFoM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ebNSASZuDvKZ",
        "outputId": "0905142a-620f-4a8c-ca29-a7881714ee0f"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0           1        337          118                  4  4.5   4.5  9.65   \n",
              "1           2        324          107                  4  4.0   4.5  8.87   \n",
              "2           3        316          104                  3  3.0   3.5  8.00   \n",
              "3           4        322          110                  3  3.5   2.5  8.67   \n",
              "4           5        314          103                  2  2.0   3.0  8.21   \n",
              "\n",
              "   Research  Chance of Admit   \n",
              "0         1              0.92  \n",
              "1         1              0.76  \n",
              "2         1              0.72  \n",
              "3         1              0.80  \n",
              "4         0              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6add5d9-4e6f-45fa-a3a1-530b5077f604\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6add5d9-4e6f-45fa-a3a1-530b5077f604')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b6add5d9-4e6f-45fa-a3a1-530b5077f604 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b6add5d9-4e6f-45fa-a3a1-530b5077f604');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set we use includes information about the probability of admission to the world's leading universities, based on the performance of applicants. Let's take a closer look at this dataset:"
      ],
      "metadata": {
        "id": "8R3GwrZ7FyXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Serial no.** - sequence number of the row (no significance)\n",
        "*   **Research** - Research experience or not (0 or 1)\n",
        "*   **GRE Score **- the applicant's GRE (Graduate Record Examinations) score (max - 340)\n",
        "*   **TOEFL Score** - the applicant's TOEFL English score (max - 120)\n",
        "*   **University Rating**- rating of the university where the applicant wants to study (max - 5)\n",
        "*   **SOP**- Evaluation of the applicant's statement of purpose (max - 5)\n",
        "* **LOR**- strength of applicant recommendation (max - 5)\n",
        "*   **CGPA**- average grade of the applicant in the previous institution of education (max - 10)\n",
        "*   **Chance of Admit** - probability of admission to the university of the applicant's choice (range [0,1])"
      ],
      "metadata": {
        "id": "Xu9j3DhiGFIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get acquainted with the technical aspects of the data set, that is, in what format, the number of rows, etc."
      ],
      "metadata": {
        "id": "Z1KHBnJoG9lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSqOTaivDvMv",
        "outputId": "6a2e02ec-8ff6-4a2d-ebfa-f47e2f8f131c"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         400 non-null    int64  \n",
            " 1   GRE Score          400 non-null    int64  \n",
            " 2   TOEFL Score        400 non-null    int64  \n",
            " 3   University Rating  400 non-null    int64  \n",
            " 4   SOP                400 non-null    float64\n",
            " 5   LOR                400 non-null    float64\n",
            " 6   CGPA               400 non-null    float64\n",
            " 7   Research           400 non-null    int64  \n",
            " 8   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 28.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the dataset consists of 400 rows and each column is in different formats (int64 and float64). Let's fit this data set to mathematical operations, specifically the linear regression process. In this case, we first convert to a numpy array for ease of calculation, choosing float64 as the column format."
      ],
      "metadata": {
        "id": "0ef4XALlHNFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = np.array(df, dtype = float)"
      ],
      "metadata": {
        "id": "veqXYtWYGz-w"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa35dju8HSPJ",
        "outputId": "e32548c6-113d-4334-e3f6-277d36ffbbfa"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract the columns from the data set for the learning process, and load them into the X variable as an array. In this case, we discard the unnecessary columns, in particular the Serial No column. Note that the last column, the Chance of Admit column, is not being loaded either, because we are loading this column into a separate variable as an array of targets."
      ],
      "metadata": {
        "id": "XqWchSZUHXX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[:, 1:8]\n",
        "X[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ituf6nDxHULa",
        "outputId": "8f847cae-91c6-4e26-b5c2-611963326371"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[337.  , 118.  ,   4.  ,   4.5 ,   4.5 ,   9.65,   1.  ],\n",
              "       [324.  , 107.  ,   4.  ,   4.  ,   4.5 ,   8.87,   1.  ],\n",
              "       [316.  , 104.  ,   3.  ,   3.  ,   3.5 ,   8.  ,   1.  ],\n",
              "       [322.  , 110.  ,   3.  ,   3.5 ,   2.5 ,   8.67,   1.  ],\n",
              "       [314.  , 103.  ,   2.  ,   2.  ,   3.  ,   8.21,   0.  ],\n",
              "       [330.  , 115.  ,   5.  ,   4.5 ,   3.  ,   9.34,   1.  ],\n",
              "       [321.  , 109.  ,   3.  ,   3.  ,   4.  ,   8.2 ,   1.  ],\n",
              "       [308.  , 101.  ,   2.  ,   3.  ,   4.  ,   7.9 ,   0.  ],\n",
              "       [302.  , 102.  ,   1.  ,   2.  ,   1.5 ,   8.  ,   0.  ],\n",
              "       [323.  , 108.  ,   3.  ,   3.5 ,   3.  ,   8.6 ,   0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGc4DsrtHvqr",
        "outputId": "29a77951-55de-4eae-aba2-44e980030fb8"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract targets from the data set, and load them into the Y variable."
      ],
      "metadata": {
        "id": "WHoQRiMnIBDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df[:,8:]\n",
        "Y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPn1tYSgH3F5",
        "outputId": "55b3a179-f2ff-4e8c-db68-d2505b8af5e6"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92],\n",
              "       [0.76],\n",
              "       [0.72],\n",
              "       [0.8 ],\n",
              "       [0.65],\n",
              "       [0.9 ],\n",
              "       [0.75],\n",
              "       [0.68],\n",
              "       [0.5 ],\n",
              "       [0.45]])"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw above, the target array consists of numbers in the range [0,1]. Let's reduce them to [0,100] for convenience in the ledgers."
      ],
      "metadata": {
        "id": "9dcQEmWSIUYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y * 100\n",
        "Y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvZcspvXIFwM",
        "outputId": "1b975b4d-f213-4aef-da48-1b9768af65cf"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[92.],\n",
              "       [76.],\n",
              "       [72.],\n",
              "       [80.],\n",
              "       [65.],\n",
              "       [90.],\n",
              "       [75.],\n",
              "       [68.],\n",
              "       [50.],\n",
              "       [45.]])"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Refinement of input variables - standardization</h1>\n",
        "\n",
        "> Let's use the standardization method for smoothing the input variables\n",
        "\n",
        "To find the arithmetic mean and root mean square deviation in the above formula, we use the mean() and std() functions in the numpy library and create a feature_scaling function that expresses this formula."
      ],
      "metadata": {
        "id": "12pf-PcjIiaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_scaling(X):\n",
        "  avg_array = np.mean(X,0)\n",
        "  std_array = np.std(X,0)\n",
        "  return np.divide(X-avg_array, std_array)"
      ],
      "metadata": {
        "id": "TIOau4weIQap"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = feature_scaling(X)"
      ],
      "metadata": {
        "id": "uuddlc3lKjrn"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8pLiMIKxKD",
        "outputId": "d123df50-39db-487a-9626-5a7b63063c1e"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.76210664,  1.74697064,  0.79882862,  1.09386422,  1.16732114,\n",
              "         1.76481828,  0.90911166],\n",
              "       [ 0.62765641, -0.06763531,  0.79882862,  0.59665321,  1.16732114,\n",
              "         0.45515126,  0.90911166],\n",
              "       [-0.07046681, -0.56252785, -0.07660001, -0.39776881,  0.05293342,\n",
              "        -1.00563118,  0.90911166]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For convenience in vertical calculations, let's add a vector whose value is to an array."
      ],
      "metadata": {
        "id": "0BoPDkK-LVBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bias(X):\n",
        "  A_0 = np.ones((X.shape[0], 1))\n",
        "  return np.hstack((A_0, X))"
      ],
      "metadata": {
        "id": "zayr9mKCLXtc"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = add_bias(X)"
      ],
      "metadata": {
        "id": "7qKQoDfvLswk"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1wMPmHLvmj",
        "outputId": "6f5c0b01-dc86-4f0e-dca2-5a26fc19aeb9"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  1.76210664,  1.74697064,  0.79882862,  1.09386422,\n",
              "         1.16732114,  1.76481828,  0.90911166],\n",
              "       [ 1.        ,  0.62765641, -0.06763531,  0.79882862,  0.59665321,\n",
              "         1.16732114,  0.45515126,  0.90911166],\n",
              "       [ 1.        , -0.07046681, -0.56252785, -0.07660001, -0.39776881,\n",
              "         0.05293342, -1.00563118,  0.90911166],\n",
              "       [ 1.        ,  0.4531256 ,  0.42725722, -0.07660001,  0.0994422 ,\n",
              "        -1.06145431,  0.11933921,  0.90911166],\n",
              "       [ 1.        , -0.24499762, -0.72749202, -0.95202863, -1.39219083,\n",
              "        -0.50426044, -0.65302852, -1.09997489]])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il2lJQGxLxRD",
        "outputId": "b586c13a-9706-4f74-e39e-b6eb696c8d83"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Split the data into training/test sets</h1>"
      ],
      "metadata": {
        "id": "yRRFgc4DPOHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split the data set we have into training/test sets. In this case, the linear regression we create will learn from the training dataset and test its performance from the test dataset. We use an 80/20 ratio for the training/test dataset split, which means we split 80% of the dataset into the training dataset and 20% into the test dataset."
      ],
      "metadata": {
        "id": "K6f4aEvRPdAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows, _ = X.shape"
      ],
      "metadata": {
        "id": "RUcoKmpKPYMh"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypNMAGc_QER3",
        "outputId": "a3388837-2432-4594-f128-92c3840b373b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(X,Y):\n",
        "  rows, _ = X.shape\n",
        "  train_rows = round(rows * 0.8)\n",
        "  test_rows = rows - train_rows\n",
        "  return X[0:train_rows, :], X[train_rows:, :], Y[0:train_rows, :], Y[train_rows:, :]"
      ],
      "metadata": {
        "id": "Wu_IvcxDQFzg"
      },
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = split(X,Y)"
      ],
      "metadata": {
        "id": "gdUonyjgQ2sG"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape:{X_train.shape},\\n\"\n",
        "      f\"X_test shape:{X_test.shape}, \\n\"\n",
        "      f\"Y_train shape:{Y_train.shape}, \\n\"\n",
        "      f\"Y_test:{Y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1uRT9TRFuY",
        "outputId": "03b60d2d-0f6d-48ba-c3eb-26a1e2c4ad48"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:(320, 8),\n",
            "X_test shape:(80, 8), \n",
            "Y_train shape:(320, 1), \n",
            "Y_test:(80, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization of coefficients**\n",
        "> We have n=7 because the data set has 7 columns (column 8 is a vector of 1's). So we have 8 coefficients, including the bias, and we can represent them in vectorized form in a 1-dimensional array. When initializing the coefficients, we use the rand function of the numpy library, which generates random numbers."
      ],
      "metadata": {
        "id": "unxrDBDUR_Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(X.shape[1], 1)"
      ],
      "metadata": {
        "id": "m3xIkLcbRw_m"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5LHxGxLSzWH",
        "outputId": "40982d8b-64c0-47dd-a6b4-2c913c203411"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.63426106],\n",
              "       [0.61443209],\n",
              "       [0.54331764],\n",
              "       [0.82283791],\n",
              "       [0.768538  ],\n",
              "       [0.36996184],\n",
              "       [0.09115052],\n",
              "       [0.25281265]])"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression function**\n",
        "> Now that we've defined the variables for the coefficients, let's define the basic function of the linear regression. Let's call this function f_x()."
      ],
      "metadata": {
        "id": "bXlh7tXfTF5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_x(X,A):\n",
        "  return np.dot(X,A)"
      ],
      "metadata": {
        "id": "hi8Hx9pCTBV1"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Value function and Gradient descent**\n",
        "> Recall the value function of linear regression:\n",
        " <br><img src=\"data:image/png;base64,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\" />"
      ],
      "metadata": {
        "id": "p4XBnPpvTlvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's express this value function in a program:**"
      ],
      "metadata": {
        "id": "bnuZ92xmUqPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(X, A, Y, m):\n",
        "  diff = f_x(X,A) - Y\n",
        "  diff_2 = np.power(diff, 2)\n",
        "  sum_ = np.sum(diff_2)\n",
        "  cost_ = sum_ / (2 * m)\n",
        "  return cost_"
      ],
      "metadata": {
        "id": "T0klFXfaTgpQ"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And in gradient descent, we find the parameters that minimize the value function above. \n",
        "\n",
        "> Let's define a number of hyperparameters in the loop implementation above.\n",
        "\n",
        "> We define the value of the number of steps as and store it in the epochs variable.\n",
        "\n",
        "> Let's define the learning rate as and store it in the learning_rate variable."
      ],
      "metadata": {
        "id": "83fiYBIlV804"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "learning_rate = 0.05"
      ],
      "metadata": {
        "id": "wGkWRolmVmTJ"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a *gradient_descent* function that performs gradient descent and\n",
        "we call it"
      ],
      "metadata": {
        "id": "CjgId74zXn3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X_train, Y_train, X_test, Y_test, A, learning_rate, epochs):\n",
        "  \n",
        "  m_train = Y_train.shape[0]\n",
        "  m_test = Y_test.shape[0]\n",
        "  train_costs = []\n",
        "  test_costs = []\n",
        "  for k in range(epochs):\n",
        "    fx = f_x(X_train, A)\n",
        "    sum_diff = np.dot(X_train.T, np.subtract(fx, Y_train)) / m_train\n",
        "    A = A - learning_rate * sum_diff\n",
        "    cost_train = cost(X_train, A, Y_train, m_train)\n",
        "    cost_test = cost(X_test, A, Y_test, m_test)\n",
        "    if k % 10 == 0:\n",
        "          print('epoch: %d, %f'% (k, cost_train))\n",
        "          print('epoch: %d, %f'% (k, cost_test))\n",
        "    train_costs.append(cost_train)\n",
        "    test_costs.append(cost_test)\n",
        "  return A, train_costs, test_costs"
      ],
      "metadata": {
        "id": "xtsKMZvoXaH0"
      },
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A, train_costs, test_costs = gradient_descent(X_train, Y_train, X_test, Y_test, A, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z__aLe7xbZxk",
        "outputId": "24568164-0fca-4a63-86fc-b6707bb26cb4"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, 2369.024585\n",
            "epoch: 0, 2364.707508\n",
            "epoch: 10, 841.397807\n",
            "epoch: 10, 993.507719\n",
            "epoch: 20, 318.660900\n",
            "epoch: 20, 406.326259\n",
            "epoch: 30, 129.719512\n",
            "epoch: 30, 177.641282\n",
            "epoch: 40, 61.014503\n",
            "epoch: 40, 87.894560\n",
            "epoch: 50, 35.823827\n",
            "epoch: 50, 51.421243\n",
            "epoch: 60, 26.458109\n",
            "epoch: 60, 35.850955\n",
            "epoch: 70, 22.888952\n",
            "epoch: 70, 28.788912\n",
            "epoch: 80, 21.467308\n",
            "epoch: 80, 25.363351\n",
            "epoch: 90, 20.856625\n",
            "epoch: 90, 23.587213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually see how much the cost function changes on the gradient descent, let's create a graph function plot_cost, which draws a graph using the matplotlib library."
      ],
      "metadata": {
        "id": "5c3XC8kmb-y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_cost(train_costs, test_costs, epochs):\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Costs\")\n",
        "  plt.plot(epochs, train_costs, 'm', linewidth=\"1\", color='r', label='error in exercise')\n",
        "  plt.plot(epochs, test_costs, 'm', linewidth=\"1\", color='g', label='error in test')\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4Kmb4ludboBk"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The *plot_cost* function accepts 3 array variables as parameters and these are:\n",
        "> an array representing the result of the value function for the training set, the train_costs variable \n",
        "\n",
        "> an array representing the result of the value function for the test set, the test_costs variable\n",
        "\n",
        ">array representing epochs, variable epochs"
      ],
      "metadata": {
        "id": "eCi2w0WIc9DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = np.arange(1, epochs + 1)\n",
        "n_train_costs = np.array(train_costs)\n",
        "n_test_costs = np.array(test_costs)"
      ],
      "metadata": {
        "id": "EHS40T_oc11u"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate loss**"
      ],
      "metadata": {
        "id": "GnMnhjigd5By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X,A,Y):\n",
        "  m = Y.shape[0]\n",
        "  fx = f_x(X, A)\n",
        "  diff = fx - Y\n",
        "  kv = np.power(diff, 2)\n",
        "  sum_kv = np.sum(kv)\n",
        "  kv_m = sum_kv / m\n",
        "  for i in range(m):\n",
        "    print('i:%d, fx:%f, Y: %f, diff: %f, kv: %f'%(i, fx[i], Y[i], diff[i], kv[i]))\n",
        "  rmse = math.sqrt(kv_m)\n",
        "  print('sum: %f, kv_m: %f, rmse: %f'%(sum_kv, kv_m, rmse))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "VgG_Dgvad02C"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('root mean squared errrors: ', calculate_loss(X_test, A, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFatCZ6wfh_y",
        "outputId": "6faac3dd-610d-40b0-b148-ec3e9bf8adbb"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:0, fx:71.047334, Y: 75.000000, diff: -3.952666, kv: 15.623566\n",
            "i:1, fx:71.986379, Y: 73.000000, diff: -1.013621, kv: 1.027428\n",
            "i:2, fx:67.149527, Y: 72.000000, diff: -4.850473, kv: 23.527090\n",
            "i:3, fx:58.335054, Y: 62.000000, diff: -3.664946, kv: 13.431827\n",
            "i:4, fx:63.807604, Y: 67.000000, diff: -3.192396, kv: 10.191391\n",
            "i:5, fx:83.986384, Y: 81.000000, diff: 2.986384, kv: 8.918487\n",
            "i:6, fx:54.739748, Y: 63.000000, diff: -8.260252, kv: 68.231768\n",
            "i:7, fx:52.196340, Y: 69.000000, diff: -16.803660, kv: 282.362987\n",
            "i:8, fx:78.582571, Y: 80.000000, diff: -1.417429, kv: 2.009106\n",
            "i:9, fx:49.138355, Y: 43.000000, diff: 6.138355, kv: 37.679396\n",
            "i:10, fx:76.193240, Y: 80.000000, diff: -3.806760, kv: 14.491423\n",
            "i:11, fx:61.068318, Y: 73.000000, diff: -11.931682, kv: 142.365036\n",
            "i:12, fx:64.253971, Y: 75.000000, diff: -10.746029, kv: 115.477145\n",
            "i:13, fx:72.419955, Y: 71.000000, diff: 1.419955, kv: 2.016273\n",
            "i:14, fx:74.356543, Y: 73.000000, diff: 1.356543, kv: 1.840208\n",
            "i:15, fx:83.663165, Y: 83.000000, diff: 0.663165, kv: 0.439787\n",
            "i:16, fx:71.263326, Y: 72.000000, diff: -0.736674, kv: 0.542689\n",
            "i:17, fx:93.999090, Y: 94.000000, diff: -0.000910, kv: 0.000001\n",
            "i:18, fx:78.592294, Y: 81.000000, diff: -2.407706, kv: 5.797047\n",
            "i:19, fx:77.485933, Y: 81.000000, diff: -3.514067, kv: 12.348668\n",
            "i:20, fx:68.687623, Y: 75.000000, diff: -6.312377, kv: 39.846107\n",
            "i:21, fx:76.668393, Y: 79.000000, diff: -2.331607, kv: 5.436392\n",
            "i:22, fx:63.987296, Y: 58.000000, diff: 5.987296, kv: 35.847710\n",
            "i:23, fx:61.100829, Y: 59.000000, diff: 2.100829, kv: 4.413483\n",
            "i:24, fx:45.176377, Y: 47.000000, diff: -1.823623, kv: 3.325599\n",
            "i:25, fx:49.724383, Y: 49.000000, diff: 0.724383, kv: 0.524731\n",
            "i:26, fx:49.834230, Y: 47.000000, diff: 2.834230, kv: 8.032858\n",
            "i:27, fx:41.168365, Y: 42.000000, diff: -0.831635, kv: 0.691617\n",
            "i:28, fx:46.236961, Y: 57.000000, diff: -10.763039, kv: 115.843014\n",
            "i:29, fx:60.709062, Y: 62.000000, diff: -1.290938, kv: 1.666520\n",
            "i:30, fx:69.509668, Y: 74.000000, diff: -4.490332, kv: 20.163080\n",
            "i:31, fx:78.104702, Y: 73.000000, diff: 5.104702, kv: 26.057984\n",
            "i:32, fx:60.492939, Y: 64.000000, diff: -3.507061, kv: 12.299476\n",
            "i:33, fx:58.855360, Y: 63.000000, diff: -4.144640, kv: 17.178045\n",
            "i:34, fx:52.101318, Y: 59.000000, diff: -6.898682, kv: 47.591817\n",
            "i:35, fx:64.560839, Y: 73.000000, diff: -8.439161, kv: 71.219436\n",
            "i:36, fx:77.733283, Y: 79.000000, diff: -1.266717, kv: 1.604572\n",
            "i:37, fx:60.779832, Y: 68.000000, diff: -7.220168, kv: 52.130821\n",
            "i:38, fx:55.853343, Y: 70.000000, diff: -14.146657, kv: 200.127902\n",
            "i:39, fx:63.345235, Y: 81.000000, diff: -17.654765, kv: 311.690716\n",
            "i:40, fx:78.898276, Y: 85.000000, diff: -6.101724, kv: 37.231033\n",
            "i:41, fx:88.773674, Y: 93.000000, diff: -4.226326, kv: 17.861832\n",
            "i:42, fx:91.538430, Y: 91.000000, diff: 0.538430, kv: 0.289907\n",
            "i:43, fx:61.922068, Y: 69.000000, diff: -7.077932, kv: 50.097119\n",
            "i:44, fx:72.821995, Y: 77.000000, diff: -4.178005, kv: 17.455723\n",
            "i:45, fx:82.862482, Y: 86.000000, diff: -3.137518, kv: 9.844021\n",
            "i:46, fx:71.721652, Y: 74.000000, diff: -2.278348, kv: 5.190871\n",
            "i:47, fx:50.164416, Y: 57.000000, diff: -6.835584, kv: 46.725202\n",
            "i:48, fx:47.350228, Y: 51.000000, diff: -3.649772, kv: 13.320834\n",
            "i:49, fx:56.239475, Y: 67.000000, diff: -10.760525, kv: 115.788894\n",
            "i:50, fx:60.399215, Y: 72.000000, diff: -11.600785, kv: 134.578203\n",
            "i:51, fx:78.837374, Y: 89.000000, diff: -10.162626, kv: 103.278976\n",
            "i:52, fx:92.680086, Y: 95.000000, diff: -2.319914, kv: 5.382000\n",
            "i:53, fx:72.000023, Y: 79.000000, diff: -6.999977, kv: 48.999671\n",
            "i:54, fx:57.251176, Y: 39.000000, diff: 18.251176, kv: 333.105419\n",
            "i:55, fx:53.349038, Y: 38.000000, diff: 15.349038, kv: 235.592961\n",
            "i:56, fx:46.594754, Y: 34.000000, diff: 12.594754, kv: 158.627839\n",
            "i:57, fx:46.896091, Y: 47.000000, diff: -0.103909, kv: 0.010797\n",
            "i:58, fx:50.539988, Y: 56.000000, diff: -5.460012, kv: 29.811727\n",
            "i:59, fx:62.063176, Y: 71.000000, diff: -8.936824, kv: 79.866816\n",
            "i:60, fx:74.971988, Y: 78.000000, diff: -3.028012, kv: 9.168858\n",
            "i:61, fx:72.055764, Y: 73.000000, diff: -0.944236, kv: 0.891581\n",
            "i:62, fx:82.199288, Y: 82.000000, diff: 0.199288, kv: 0.039716\n",
            "i:63, fx:61.043477, Y: 62.000000, diff: -0.956523, kv: 0.914936\n",
            "i:64, fx:94.238264, Y: 96.000000, diff: -1.761736, kv: 3.103712\n",
            "i:65, fx:96.985850, Y: 96.000000, diff: 0.985850, kv: 0.971900\n",
            "i:66, fx:58.165024, Y: 46.000000, diff: 12.165024, kv: 147.987809\n",
            "i:67, fx:62.040494, Y: 53.000000, diff: 9.040494, kv: 81.730529\n",
            "i:68, fx:49.664219, Y: 49.000000, diff: 0.664219, kv: 0.441187\n",
            "i:69, fx:73.200963, Y: 76.000000, diff: -2.799037, kv: 7.834610\n",
            "i:70, fx:60.519016, Y: 64.000000, diff: -3.480984, kv: 12.117247\n",
            "i:71, fx:68.968093, Y: 71.000000, diff: -2.031907, kv: 4.128646\n",
            "i:72, fx:81.863211, Y: 84.000000, diff: -2.136789, kv: 4.565868\n",
            "i:73, fx:67.933079, Y: 77.000000, diff: -9.066921, kv: 82.209055\n",
            "i:74, fx:84.281260, Y: 89.000000, diff: -4.718740, kv: 22.266511\n",
            "i:75, fx:78.618590, Y: 82.000000, diff: -3.381410, kv: 11.433933\n",
            "i:76, fx:77.795286, Y: 84.000000, diff: -6.204714, kv: 38.498478\n",
            "i:77, fx:90.125151, Y: 91.000000, diff: -0.874849, kv: 0.765361\n",
            "i:78, fx:70.476269, Y: 67.000000, diff: 3.476269, kv: 12.084450\n",
            "i:79, fx:91.636141, Y: 95.000000, diff: -3.363859, kv: 11.315547\n",
            "sum: 3629.542984, kv_m: 45.369287, rmse: 6.735673\n",
            "root mean squared errrors:  6.735672743359764\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get acquainted with the values ​​of the optimal coefficients found by gradient descent:"
      ],
      "metadata": {
        "id": "Uv4tpOQqfyzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYw7R2vFfoC8",
        "outputId": "9ac01076-2cbf-4a40-b4ff-861f2accef77"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[71.56428001],\n",
              "       [ 2.14643691],\n",
              "       [ 2.91693739],\n",
              "       [ 1.2509758 ],\n",
              "       [ 0.29815833],\n",
              "       [ 2.28958284],\n",
              "       [ 4.94497825],\n",
              "       [ 0.8179122 ]])"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's graphically represent the change of the cost function at each step using the plot_cost function."
      ],
      "metadata": {
        "id": "egwHjr7EgD_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "figure(figsize=(8,6), dpi=80)\n",
        "\n",
        "plot_cost(train_costs, test_costs, n_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 523
        },
        "id": "zSIEna7XfuWZ",
        "outputId": "00238a75-c20a-4d48-fe36-6625ab6d4d93"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-115-f1fb3824de42>:4: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"m\" (-> color=(0.75, 0.0, 0.75, 1)). The keyword argument will take precedence.\n",
            "  plt.plot(epochs, train_costs, 'm', linewidth=\"1\", color='r', label='error in exercise')\n",
            "<ipython-input-115-f1fb3824de42>:5: UserWarning: color is redundantly defined by the 'color' keyword argument and the fmt string \"m\" (-> color=(0.75, 0.0, 0.75, 1)). The keyword argument will take precedence.\n",
            "  plt.plot(epochs, test_costs, 'm', linewidth=\"1\", color='g', label='error in test')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the graph above, we can see that the error is decreasing at each step in both the training set and the test set. From this we can conclude that the linear regression we created is working correctly."
      ],
      "metadata": {
        "id": "V88PmIo_j14A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now in practice, let's predict the first 10 rows in the test set using the coefficients found by linear regression and check with real targets:"
      ],
      "metadata": {
        "id": "yDPXESJRkDxx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "m_to_predict = 10\n",
        "\n",
        "predicted = f_x(X_test[:m_to_predict, :], A)\n",
        "\n",
        "for i in range(m_to_predict):\n",
        "  print('bashorat: %f, haqiqiy: %f'% (predicted[i], Y_test[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8QmZR06kJ0C",
        "outputId": "550343fe-ba73-4f2f-ecf3-f3beccbb91e8"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bashorat: 71.047334, haqiqiy: 75.000000\n",
            "bashorat: 71.986379, haqiqiy: 73.000000\n",
            "bashorat: 67.149527, haqiqiy: 72.000000\n",
            "bashorat: 58.335054, haqiqiy: 62.000000\n",
            "bashorat: 63.807604, haqiqiy: 67.000000\n",
            "bashorat: 83.986384, haqiqiy: 81.000000\n",
            "bashorat: 54.739748, haqiqiy: 63.000000\n",
            "bashorat: 52.196340, haqiqiy: 69.000000\n",
            "bashorat: 78.582571, haqiqiy: 80.000000\n",
            "bashorat: 49.138355, haqiqiy: 43.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the predicted targets are close to the values of the actual targets, although with some error."
      ],
      "metadata": {
        "id": "RbwmBHDTk5oP"
      }
    }
  ]
}