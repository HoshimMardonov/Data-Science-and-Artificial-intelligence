{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1JfHmrNmmPo3NFrVJaAgjLKfcCWFYia-h",
      "authorship_tag": "ABX9TyOvpWxXWA0qxSpmW7Ok9NjR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HoshimMardonov/Datasets/blob/main/graduate_admissions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Vi93WjNaDKuk"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import figure\n",
        "\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We load dataFrame using the pandas library\n"
      ],
      "metadata": {
        "id": "T0amMTlTEgDy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Rhtyme/ml_uz_book/main/practice_session/Multivariate_linear_regression_4_6/Admission_Predict.csv\")"
      ],
      "metadata": {
        "id": "qgYH0cjuDvIV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "***Let's get acquainted with the database, that is, what columns there are, and what the data in them looks like, etc.***"
      ],
      "metadata": {
        "id": "oC5QOITaFoM0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "ebNSASZuDvKZ",
        "outputId": "5c1c8631-32c5-40d3-b7fe-297e9a2a8c24"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0           1        337          118                  4  4.5   4.5  9.65   \n",
              "1           2        324          107                  4  4.0   4.5  8.87   \n",
              "2           3        316          104                  3  3.0   3.5  8.00   \n",
              "3           4        322          110                  3  3.5   2.5  8.67   \n",
              "4           5        314          103                  2  2.0   3.0  8.21   \n",
              "\n",
              "   Research  Chance of Admit   \n",
              "0         1              0.92  \n",
              "1         1              0.76  \n",
              "2         1              0.72  \n",
              "3         1              0.80  \n",
              "4         0              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0f2e4bb9-1ce2-4a25-b69a-9020e6da32a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0f2e4bb9-1ce2-4a25-b69a-9020e6da32a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0f2e4bb9-1ce2-4a25-b69a-9020e6da32a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0f2e4bb9-1ce2-4a25-b69a-9020e6da32a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data set we use includes information about the probability of admission to the world's leading universities, based on the performance of applicants. Let's take a closer look at this dataset:"
      ],
      "metadata": {
        "id": "8R3GwrZ7FyXs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Serial no.** - sequence number of the row (no significance)\n",
        "*   **Research** - Research experience or not (0 or 1)\n",
        "*   **GRE Score **- the applicant's GRE (Graduate Record Examinations) score (max - 340)\n",
        "*   **TOEFL Score** - the applicant's TOEFL English score (max - 120)\n",
        "*   **University Rating**- rating of the university where the applicant wants to study (max - 5)\n",
        "*   **SOP**- Evaluation of the applicant's statement of purpose (max - 5)\n",
        "* **LOR**- strength of applicant recommendation (max - 5)\n",
        "*   **CGPA**- average grade of the applicant in the previous institution of education (max - 10)\n",
        "*   **Chance of Admit** - probability of admission to the university of the applicant's choice (range [0,1])"
      ],
      "metadata": {
        "id": "Xu9j3DhiGFIc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's get acquainted with the technical aspects of the data set, that is, in what format, the number of rows, etc."
      ],
      "metadata": {
        "id": "Z1KHBnJoG9lD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSqOTaivDvMv",
        "outputId": "f8fcdba4-b9eb-49cc-a12e-044f1133561e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 400 entries, 0 to 399\n",
            "Data columns (total 9 columns):\n",
            " #   Column             Non-Null Count  Dtype  \n",
            "---  ------             --------------  -----  \n",
            " 0   Serial No.         400 non-null    int64  \n",
            " 1   GRE Score          400 non-null    int64  \n",
            " 2   TOEFL Score        400 non-null    int64  \n",
            " 3   University Rating  400 non-null    int64  \n",
            " 4   SOP                400 non-null    float64\n",
            " 5   LOR                400 non-null    float64\n",
            " 6   CGPA               400 non-null    float64\n",
            " 7   Research           400 non-null    int64  \n",
            " 8   Chance of Admit    400 non-null    float64\n",
            "dtypes: float64(4), int64(5)\n",
            "memory usage: 28.2 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the dataset consists of 400 rows and each column is in different formats (int64 and float64). Let's fit this data set to mathematical operations, specifically the linear regression process. In this case, we first convert to a numpy array for ease of calculation, choosing float64 as the column format."
      ],
      "metadata": {
        "id": "0ef4XALlHNFb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = np.array(df, dtype = float)"
      ],
      "metadata": {
        "id": "veqXYtWYGz-w"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aa35dju8HSPJ",
        "outputId": "710d487b-7e86-4a7e-dcac-66bf7db5fe2d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400, 9)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract the columns from the data set for the learning process, and load them into the X variable as an array. In this case, we discard the unnecessary columns, in particular the Serial No column. Note that the last column, the Chance of Admit column, is not being loaded either, because we are loading this column into a separate variable as an array of targets."
      ],
      "metadata": {
        "id": "XqWchSZUHXX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[:, 1:8]\n",
        "X[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ituf6nDxHULa",
        "outputId": "9d46374f-5908-4a80-df62-5e4ae5f2b844"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[337.  , 118.  ,   4.  ,   4.5 ,   4.5 ,   9.65,   1.  ],\n",
              "       [324.  , 107.  ,   4.  ,   4.  ,   4.5 ,   8.87,   1.  ],\n",
              "       [316.  , 104.  ,   3.  ,   3.  ,   3.5 ,   8.  ,   1.  ],\n",
              "       [322.  , 110.  ,   3.  ,   3.5 ,   2.5 ,   8.67,   1.  ],\n",
              "       [314.  , 103.  ,   2.  ,   2.  ,   3.  ,   8.21,   0.  ],\n",
              "       [330.  , 115.  ,   5.  ,   4.5 ,   3.  ,   9.34,   1.  ],\n",
              "       [321.  , 109.  ,   3.  ,   3.  ,   4.  ,   8.2 ,   1.  ],\n",
              "       [308.  , 101.  ,   2.  ,   3.  ,   4.  ,   7.9 ,   0.  ],\n",
              "       [302.  , 102.  ,   1.  ,   2.  ,   1.5 ,   8.  ,   0.  ],\n",
              "       [323.  , 108.  ,   3.  ,   3.5 ,   3.  ,   8.6 ,   0.  ]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UGc4DsrtHvqr",
        "outputId": "f828ddd3-dc14-4e0d-c909-055741f63884"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We extract targets from the data set, and load them into the Y variable."
      ],
      "metadata": {
        "id": "WHoQRiMnIBDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = df[:,8:]\n",
        "Y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPn1tYSgH3F5",
        "outputId": "9f1ece72-4236-467b-e03c-6b05a59afaf4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.92],\n",
              "       [0.76],\n",
              "       [0.72],\n",
              "       [0.8 ],\n",
              "       [0.65],\n",
              "       [0.9 ],\n",
              "       [0.75],\n",
              "       [0.68],\n",
              "       [0.5 ],\n",
              "       [0.45]])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we saw above, the target array consists of numbers in the range [0,1]. Let's reduce them to [0,100] for convenience in the ledgers."
      ],
      "metadata": {
        "id": "9dcQEmWSIUYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = Y * 100\n",
        "Y[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CvZcspvXIFwM",
        "outputId": "8df636d8-0334-406f-f689-4d416faf9d9b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[92.],\n",
              "       [76.],\n",
              "       [72.],\n",
              "       [80.],\n",
              "       [65.],\n",
              "       [90.],\n",
              "       [75.],\n",
              "       [68.],\n",
              "       [50.],\n",
              "       [45.]])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Refinement of input variables - standardization</h1>\n",
        "\n",
        "> Let's use the standardization method for smoothing the input variables\n",
        "\n",
        "To find the arithmetic mean and root mean square deviation in the above formula, we use the mean() and std() functions in the numpy library and create a feature_scaling function that expresses this formula."
      ],
      "metadata": {
        "id": "12pf-PcjIiaO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def feature_scaling(X):\n",
        "  avg_array = np.mean(X,0)\n",
        "  std_array = np.std(X,0)\n",
        "  return np.divide(X-avg_array, std_array)"
      ],
      "metadata": {
        "id": "TIOau4weIQap"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = feature_scaling(X)"
      ],
      "metadata": {
        "id": "uuddlc3lKjrn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-V8pLiMIKxKD",
        "outputId": "e89321cb-8772-4962-e98c-c111824312a3"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.76210664,  1.74697064,  0.79882862,  1.09386422,  1.16732114,\n",
              "         1.76481828,  0.90911166],\n",
              "       [ 0.62765641, -0.06763531,  0.79882862,  0.59665321,  1.16732114,\n",
              "         0.45515126,  0.90911166],\n",
              "       [-0.07046681, -0.56252785, -0.07660001, -0.39776881,  0.05293342,\n",
              "        -1.00563118,  0.90911166]])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For convenience in vertical calculations, let's add a vector whose value is to an array."
      ],
      "metadata": {
        "id": "0BoPDkK-LVBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_bias(X):\n",
        "  A_0 = np.ones((X.shape[0], 1))\n",
        "  return np.hstack((A_0, X))"
      ],
      "metadata": {
        "id": "zayr9mKCLXtc"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = add_bias(X)"
      ],
      "metadata": {
        "id": "7qKQoDfvLswk"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-1wMPmHLvmj",
        "outputId": "0f9d39e3-a287-449c-bafe-6fd00cc5ca81"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 1.        ,  1.76210664,  1.74697064,  0.79882862,  1.09386422,\n",
              "         1.16732114,  1.76481828,  0.90911166],\n",
              "       [ 1.        ,  0.62765641, -0.06763531,  0.79882862,  0.59665321,\n",
              "         1.16732114,  0.45515126,  0.90911166],\n",
              "       [ 1.        , -0.07046681, -0.56252785, -0.07660001, -0.39776881,\n",
              "         0.05293342, -1.00563118,  0.90911166],\n",
              "       [ 1.        ,  0.4531256 ,  0.42725722, -0.07660001,  0.0994422 ,\n",
              "        -1.06145431,  0.11933921,  0.90911166],\n",
              "       [ 1.        , -0.24499762, -0.72749202, -0.95202863, -1.39219083,\n",
              "        -0.50426044, -0.65302852, -1.09997489]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "il2lJQGxLxRD",
        "outputId": "cce367d8-7495-40a1-dd4c-65736a629419"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1>Split the data into training/test sets</h1>"
      ],
      "metadata": {
        "id": "yRRFgc4DPOHs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split the data set we have into training/test sets. In this case, the linear regression we create will learn from the training dataset and test its performance from the test dataset. We use an 80/20 ratio for the training/test dataset split, which means we split 80% of the dataset into the training dataset and 20% into the test dataset."
      ],
      "metadata": {
        "id": "K6f4aEvRPdAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rows, _ = X.shape"
      ],
      "metadata": {
        "id": "RUcoKmpKPYMh"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rows"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypNMAGc_QER3",
        "outputId": "d22a672d-9c4a-4c1c-cd42-8487a40eb3ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "400"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split(X,Y):\n",
        "  rows, _ = X.shape\n",
        "  train_rows = round(rows * 0.8)\n",
        "  test_rows = rows - train_rows\n",
        "  return X[0:train_rows, :], X[train_rows:, :], Y[0:train_rows, :], Y[train_rows:, :]"
      ],
      "metadata": {
        "id": "Wu_IvcxDQFzg"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = split(X,Y)"
      ],
      "metadata": {
        "id": "gdUonyjgQ2sG"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"X_train shape:{X_train.shape},\\n\"\n",
        "      f\"X_test shape:{X_test.shape}, \\n\"\n",
        "      f\"Y_train shape:{Y_train.shape}, \\n\"\n",
        "      f\"Y_test:{Y_test.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yq1uRT9TRFuY",
        "outputId": "6da38663-ee1c-44f6-cde6-57742aedb38e"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape:(320, 8),\n",
            "X_test shape:(80, 8), \n",
            "Y_train shape:(320, 1), \n",
            "Y_test:(80, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initialization of coefficients**\n",
        "> We have n=7 because the data set has 7 columns (column 8 is a vector of 1's). So we have 8 coefficients, including the bias, and we can represent them in vectorized form in a 1-dimensional array. When initializing the coefficients, we use the rand function of the numpy library, which generates random numbers."
      ],
      "metadata": {
        "id": "unxrDBDUR_Bq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A = np.random.rand(X.shape[1], 1)"
      ],
      "metadata": {
        "id": "m3xIkLcbRw_m"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5LHxGxLSzWH",
        "outputId": "fcfd4962-cd6f-4e6a-838b-ffe0864fc89c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.87070056],\n",
              "       [0.71449924],\n",
              "       [0.22108789],\n",
              "       [0.37888972],\n",
              "       [0.10219905],\n",
              "       [0.95032947],\n",
              "       [0.92942434],\n",
              "       [0.06957482]])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Linear regression function**\n",
        "> Now that we've defined the variables for the coefficients, let's define the basic function of the linear regression. Let's call this function f_x()."
      ],
      "metadata": {
        "id": "bXlh7tXfTF5q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def f_x(X,A):\n",
        "  return np.dot(X,A)"
      ],
      "metadata": {
        "id": "hi8Hx9pCTBV1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Value function and Gradient descent**\n",
        "> Recall the value function of linear regression:\n",
        " <br><img src=\"data:image/png;base64,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\" />"
      ],
      "metadata": {
        "id": "p4XBnPpvTlvR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's express this value function in a program:**"
      ],
      "metadata": {
        "id": "bnuZ92xmUqPR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def cost(X, A, Y, m):\n",
        "  diff = f_x(X,A) - Y\n",
        "  diff_2 = np.power(diff, 2)\n",
        "  sum_ = np.sum(diff_2)\n",
        "  cost_ = sum_ / (2 * m)\n",
        "  return cost_"
      ],
      "metadata": {
        "id": "T0klFXfaTgpQ"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And in gradient descent, we find the parameters that minimize the value function above. \n",
        "\n",
        "> Let's define a number of hyperparameters in the loop implementation above.\n",
        "\n",
        "> We define the value of the number of steps as and store it in the epochs variable.\n",
        "\n",
        "> Let's define the learning rate as and store it in the learning_rate variable."
      ],
      "metadata": {
        "id": "83fiYBIlV804"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 500\n",
        "learning_rate = 0.05"
      ],
      "metadata": {
        "id": "wGkWRolmVmTJ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We create a *gradient_descent* function that performs gradient descent and\n",
        "we call it"
      ],
      "metadata": {
        "id": "CjgId74zXn3s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gradient_descent(X_train, Y_train, X_test, Y_test, A, learning_rate, epochs):\n",
        "  \n",
        "  m_train = Y_train.shape[0]\n",
        "  m_test = Y_test.shape[0]\n",
        "  train_costs = []\n",
        "  test_costs = []\n",
        "  for k in range(epochs):\n",
        "    fx = f_x(X_train, A)\n",
        "    sum_diff = np.dot(X_train.T, np.subtract(fx, Y_train)) / m_train\n",
        "    A = A - learning_rate * sum_diff\n",
        "    cost_train = cost(X_train, A, Y_train, m_train)\n",
        "    cost_test = cost(X_test, A, Y_test, m_test)\n",
        "    if k % 10 == 0:\n",
        "          print('epoch: %d, %f'% (k, cost_train))\n",
        "          print('epoch: %d, %f'% (k, cost_test))\n",
        "    train_costs.append(cost_train)\n",
        "    test_costs.append(cost_test)\n",
        "  return A, train_costs, test_costs"
      ],
      "metadata": {
        "id": "xtsKMZvoXaH0"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "A, train_costs, test_costs = gradient_descent(X_train, Y_train, X_test, Y_test, A, learning_rate, epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z__aLe7xbZxk",
        "outputId": "73f3e509-f78d-46f3-c142-6fdb9e2e53f5"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0, 2353.246555\n",
            "epoch: 0, 2345.031902\n",
            "epoch: 10, 834.991123\n",
            "epoch: 10, 984.776161\n",
            "epoch: 20, 315.785355\n",
            "epoch: 20, 402.350982\n",
            "epoch: 30, 128.231285\n",
            "epoch: 30, 175.697318\n",
            "epoch: 40, 60.119380\n",
            "epoch: 40, 86.863343\n",
            "epoch: 50, 35.216213\n",
            "epoch: 50, 50.827262\n",
            "epoch: 60, 26.012037\n",
            "epoch: 60, 35.481298\n",
            "epoch: 70, 22.546539\n",
            "epoch: 70, 28.542467\n",
            "epoch: 80, 21.197968\n",
            "epoch: 80, 25.189048\n",
            "epoch: 90, 20.641794\n",
            "epoch: 90, 23.457649\n",
            "epoch: 100, 20.389657\n",
            "epoch: 100, 22.509356\n",
            "epoch: 110, 20.259279\n",
            "epoch: 110, 21.964192\n",
            "epoch: 120, 20.181276\n",
            "epoch: 120, 21.638671\n",
            "epoch: 130, 20.128365\n",
            "epoch: 130, 21.438433\n",
            "epoch: 140, 20.089215\n",
            "epoch: 140, 21.312172\n",
            "epoch: 150, 20.058702\n",
            "epoch: 150, 21.230711\n",
            "epoch: 160, 20.034222\n",
            "epoch: 160, 21.176886\n",
            "epoch: 170, 20.014263\n",
            "epoch: 170, 21.140346\n",
            "epoch: 180, 19.997837\n",
            "epoch: 180, 21.114743\n",
            "epoch: 190, 19.984238\n",
            "epoch: 190, 21.096134\n",
            "epoch: 200, 19.972931\n",
            "epoch: 200, 21.082048\n",
            "epoch: 210, 19.963501\n",
            "epoch: 210, 21.070926\n",
            "epoch: 220, 19.955615\n",
            "epoch: 220, 21.061779\n",
            "epoch: 230, 19.949006\n",
            "epoch: 230, 21.053980\n",
            "epoch: 240, 19.943454\n",
            "epoch: 240, 21.047127\n",
            "epoch: 250, 19.938783\n",
            "epoch: 250, 21.040962\n",
            "epoch: 260, 19.934846\n",
            "epoch: 260, 21.035319\n",
            "epoch: 270, 19.931524\n",
            "epoch: 270, 21.030091\n",
            "epoch: 280, 19.928715\n",
            "epoch: 280, 21.025208\n",
            "epoch: 290, 19.926339\n",
            "epoch: 290, 21.020624\n",
            "epoch: 300, 19.924325\n",
            "epoch: 300, 21.016306\n",
            "epoch: 310, 19.922618\n",
            "epoch: 310, 21.012233\n",
            "epoch: 320, 19.921168\n",
            "epoch: 320, 21.008387\n",
            "epoch: 330, 19.919937\n",
            "epoch: 330, 21.004757\n",
            "epoch: 340, 19.918890\n",
            "epoch: 340, 21.001330\n",
            "epoch: 350, 19.917999\n",
            "epoch: 350, 20.998099\n",
            "epoch: 360, 19.917240\n",
            "epoch: 360, 20.995053\n",
            "epoch: 370, 19.916594\n",
            "epoch: 370, 20.992186\n",
            "epoch: 380, 19.916043\n",
            "epoch: 380, 20.989489\n",
            "epoch: 390, 19.915574\n",
            "epoch: 390, 20.986954\n",
            "epoch: 400, 19.915173\n",
            "epoch: 400, 20.984574\n",
            "epoch: 410, 19.914831\n",
            "epoch: 410, 20.982341\n",
            "epoch: 420, 19.914538\n",
            "epoch: 420, 20.980248\n",
            "epoch: 430, 19.914289\n",
            "epoch: 430, 20.978288\n",
            "epoch: 440, 19.914076\n",
            "epoch: 440, 20.976453\n",
            "epoch: 450, 19.913893\n",
            "epoch: 450, 20.974738\n",
            "epoch: 460, 19.913737\n",
            "epoch: 460, 20.973135\n",
            "epoch: 470, 19.913604\n",
            "epoch: 470, 20.971637\n",
            "epoch: 480, 19.913490\n",
            "epoch: 480, 20.970240\n",
            "epoch: 490, 19.913392\n",
            "epoch: 490, 20.968936\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visually see how much the cost function changes on the gradient descent, let's create a graph function plot_cost, which draws a graph using the matplotlib library."
      ],
      "metadata": {
        "id": "5c3XC8kmb-y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_costs(train_costs, test_costs, epochs):\n",
        "  plt.xlabel(\"Epochs\")\n",
        "  plt.ylabel(\"Costs\")\n",
        "  plt.plot(epochs, train_costs, 'm', linewidth=\"1\", color='r', label='error in exercise')\n",
        "  plt.plot(epochs, test_costs, 'm', linewidth=\"1\", color='g', label='error in test')\n",
        "  plt.legend(loc=\"upper right\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "4Kmb4ludboBk"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The plot_cost function accepts 3 array variables as parameters and these are:\n",
        "> an array representing the result of the value function for the training set, the train_costs variable \n",
        "\n",
        "> an array representing the result of the value function for the test set, the test_costs variable\n",
        "\n",
        ">array representing epochs, variable epochs"
      ],
      "metadata": {
        "id": "eCi2w0WIc9DI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_epochs = np.arange(1, epochs + 1)\n",
        "n_train_costs = np.array(train_costs)\n",
        "n_test_costs = np.array(test_costs)"
      ],
      "metadata": {
        "id": "EHS40T_oc11u"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Calculate loss**"
      ],
      "metadata": {
        "id": "GnMnhjigd5By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss(X,A,Y):\n",
        "  m = Y.shape[0]\n",
        "  fx = f_x(X, A)\n",
        "  diff = fx - Y\n",
        "  kv = np.power(diff, 2)\n",
        "  sum_kv = np.sum(kv)\n",
        "  kv_m = sum_kv / m\n",
        "  for i in range(m):\n",
        "    print('i:%d, fx:%f, Y: %f, diff: %f, kv: %f'%(i, fx[i], Y[i], diff[i], kv[i]))\n",
        "  rmse = math.sqrt(kv_m)\n",
        "  print('sum: %f, kv_m: %f, rmse: %f'%(sum_kv, kv_m, rmse))\n",
        "  return rmse"
      ],
      "metadata": {
        "id": "VgG_Dgvad02C"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('root mean squared errrors: ', calculate_loss(X_test, A, Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hFatCZ6wfh_y",
        "outputId": "ae2e2cd9-8f55-4998-d2d1-5c972463aa1a"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "i:0, fx:71.098063, Y: 75.000000, diff: -3.901937, kv: 15.225110\n",
            "i:1, fx:72.227520, Y: 73.000000, diff: -0.772480, kv: 0.596726\n",
            "i:2, fx:67.711170, Y: 72.000000, diff: -4.288830, kv: 18.394062\n",
            "i:3, fx:59.710146, Y: 62.000000, diff: -2.289854, kv: 5.243434\n",
            "i:4, fx:64.088114, Y: 67.000000, diff: -2.911886, kv: 8.479082\n",
            "i:5, fx:84.697024, Y: 81.000000, diff: 3.697024, kv: 13.667984\n",
            "i:6, fx:55.713596, Y: 63.000000, diff: -7.286404, kv: 53.091683\n",
            "i:7, fx:52.342264, Y: 69.000000, diff: -16.657736, kv: 277.480155\n",
            "i:8, fx:78.095554, Y: 80.000000, diff: -1.904446, kv: 3.626914\n",
            "i:9, fx:50.125877, Y: 43.000000, diff: 7.125877, kv: 50.778120\n",
            "i:10, fx:75.655665, Y: 80.000000, diff: -4.344335, kv: 18.873248\n",
            "i:11, fx:60.887316, Y: 73.000000, diff: -12.112684, kv: 146.717117\n",
            "i:12, fx:63.702263, Y: 75.000000, diff: -11.297737, kv: 127.638863\n",
            "i:13, fx:73.052358, Y: 71.000000, diff: 2.052358, kv: 4.212172\n",
            "i:14, fx:74.259093, Y: 73.000000, diff: 1.259093, kv: 1.585316\n",
            "i:15, fx:84.660627, Y: 83.000000, diff: 1.660627, kv: 2.757682\n",
            "i:16, fx:71.881589, Y: 72.000000, diff: -0.118411, kv: 0.014021\n",
            "i:17, fx:93.843178, Y: 94.000000, diff: -0.156822, kv: 0.024593\n",
            "i:18, fx:78.634310, Y: 81.000000, diff: -2.365690, kv: 5.596491\n",
            "i:19, fx:77.856311, Y: 81.000000, diff: -3.143689, kv: 9.882779\n",
            "i:20, fx:69.233210, Y: 75.000000, diff: -5.766790, kv: 33.255870\n",
            "i:21, fx:77.118839, Y: 79.000000, diff: -1.881161, kv: 3.538768\n",
            "i:22, fx:63.846946, Y: 58.000000, diff: 5.846946, kv: 34.186781\n",
            "i:23, fx:61.950409, Y: 59.000000, diff: 2.950409, kv: 8.704911\n",
            "i:24, fx:45.394435, Y: 47.000000, diff: -1.605565, kv: 2.577840\n",
            "i:25, fx:49.772951, Y: 49.000000, diff: 0.772951, kv: 0.597453\n",
            "i:26, fx:50.695015, Y: 47.000000, diff: 3.695015, kv: 13.653136\n",
            "i:27, fx:42.091308, Y: 42.000000, diff: 0.091308, kv: 0.008337\n",
            "i:28, fx:45.325012, Y: 57.000000, diff: -11.674988, kv: 136.305337\n",
            "i:29, fx:61.166637, Y: 62.000000, diff: -0.833363, kv: 0.694493\n",
            "i:30, fx:69.472643, Y: 74.000000, diff: -4.527357, kv: 20.496957\n",
            "i:31, fx:78.177695, Y: 73.000000, diff: 5.177695, kv: 26.808524\n",
            "i:32, fx:61.486816, Y: 64.000000, diff: -2.513184, kv: 6.316092\n",
            "i:33, fx:58.790601, Y: 63.000000, diff: -4.209399, kv: 17.719043\n",
            "i:34, fx:52.378857, Y: 59.000000, diff: -6.621143, kv: 43.839530\n",
            "i:35, fx:65.079392, Y: 73.000000, diff: -7.920608, kv: 62.736033\n",
            "i:36, fx:78.495980, Y: 79.000000, diff: -0.504020, kv: 0.254036\n",
            "i:37, fx:60.125260, Y: 68.000000, diff: -7.874740, kv: 62.011536\n",
            "i:38, fx:54.289878, Y: 70.000000, diff: -15.710122, kv: 246.807943\n",
            "i:39, fx:64.179325, Y: 81.000000, diff: -16.820675, kv: 282.935099\n",
            "i:40, fx:78.956282, Y: 85.000000, diff: -6.043718, kv: 36.526524\n",
            "i:41, fx:89.881068, Y: 93.000000, diff: -3.118932, kv: 9.727740\n",
            "i:42, fx:91.479893, Y: 91.000000, diff: 0.479893, kv: 0.230297\n",
            "i:43, fx:63.374868, Y: 69.000000, diff: -5.625132, kv: 31.642113\n",
            "i:44, fx:75.465595, Y: 77.000000, diff: -1.534405, kv: 2.354399\n",
            "i:45, fx:82.667497, Y: 86.000000, diff: -3.332503, kv: 11.105578\n",
            "i:46, fx:72.226811, Y: 74.000000, diff: -1.773189, kv: 3.144200\n",
            "i:47, fx:50.923376, Y: 57.000000, diff: -6.076624, kv: 36.925359\n",
            "i:48, fx:49.764798, Y: 51.000000, diff: -1.235202, kv: 1.525723\n",
            "i:49, fx:58.472090, Y: 67.000000, diff: -8.527910, kv: 72.725243\n",
            "i:50, fx:61.290012, Y: 72.000000, diff: -10.709988, kv: 114.703838\n",
            "i:51, fx:80.672525, Y: 89.000000, diff: -8.327475, kv: 69.346845\n",
            "i:52, fx:93.172769, Y: 95.000000, diff: -1.827231, kv: 3.338772\n",
            "i:53, fx:72.306165, Y: 79.000000, diff: -6.693835, kv: 44.807424\n",
            "i:54, fx:56.242171, Y: 39.000000, diff: 17.242171, kv: 297.292467\n",
            "i:55, fx:53.255248, Y: 38.000000, diff: 15.255248, kv: 232.722599\n",
            "i:56, fx:46.228230, Y: 34.000000, diff: 12.228230, kv: 149.529605\n",
            "i:57, fx:47.401625, Y: 47.000000, diff: 0.401625, kv: 0.161303\n",
            "i:58, fx:51.187439, Y: 56.000000, diff: -4.812561, kv: 23.160742\n",
            "i:59, fx:64.822108, Y: 71.000000, diff: -6.177892, kv: 38.166345\n",
            "i:60, fx:76.928448, Y: 78.000000, diff: -1.071552, kv: 1.148224\n",
            "i:61, fx:73.639844, Y: 73.000000, diff: 0.639844, kv: 0.409401\n",
            "i:62, fx:82.980834, Y: 82.000000, diff: 0.980834, kv: 0.962035\n",
            "i:63, fx:62.278590, Y: 62.000000, diff: 0.278590, kv: 0.077612\n",
            "i:64, fx:95.938326, Y: 96.000000, diff: -0.061674, kv: 0.003804\n",
            "i:65, fx:98.081839, Y: 96.000000, diff: 2.081839, kv: 4.334055\n",
            "i:66, fx:58.874270, Y: 46.000000, diff: 12.874270, kv: 165.746838\n",
            "i:67, fx:62.827036, Y: 53.000000, diff: 9.827036, kv: 96.570636\n",
            "i:68, fx:51.159288, Y: 49.000000, diff: 2.159288, kv: 4.662525\n",
            "i:69, fx:73.194339, Y: 76.000000, diff: -2.805661, kv: 7.871734\n",
            "i:70, fx:61.948014, Y: 64.000000, diff: -2.051986, kv: 4.210647\n",
            "i:71, fx:70.827283, Y: 71.000000, diff: -0.172717, kv: 0.029831\n",
            "i:72, fx:82.464771, Y: 84.000000, diff: -1.535229, kv: 2.356927\n",
            "i:73, fx:69.896866, Y: 77.000000, diff: -7.103134, kv: 50.454508\n",
            "i:74, fx:85.063331, Y: 89.000000, diff: -3.936669, kv: 15.497362\n",
            "i:75, fx:79.995083, Y: 82.000000, diff: -2.004917, kv: 4.019693\n",
            "i:76, fx:80.337122, Y: 84.000000, diff: -3.662878, kv: 13.416677\n",
            "i:77, fx:90.398227, Y: 91.000000, diff: -0.601773, kv: 0.362130\n",
            "i:78, fx:72.350419, Y: 67.000000, diff: 5.350419, kv: 28.626979\n",
            "i:79, fx:92.239169, Y: 95.000000, diff: -2.760831, kv: 7.622188\n",
            "sum: 3354.854193, kv_m: 41.935677, rmse: 6.475776\n",
            "root mean squared errrors:  6.475776201373876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also get acquainted with the values ​​of the optimal coefficients found by gradient descent:"
      ],
      "metadata": {
        "id": "Uv4tpOQqfyzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "A"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYw7R2vFfoC8",
        "outputId": "df367c5b-3106-42ba-df21-fbaa512a76b4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[72.05627862],\n",
              "       [ 1.97077535],\n",
              "       [ 1.83395072],\n",
              "       [ 0.99746877],\n",
              "       [-0.54829018],\n",
              "       [ 2.49947074],\n",
              "       [ 6.84950509],\n",
              "       [ 0.92860324]])"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's graphically represent the change of the cost function at each step using the plot_cost function."
      ],
      "metadata": {
        "id": "egwHjr7EgD_e"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSIEna7XfuWZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}